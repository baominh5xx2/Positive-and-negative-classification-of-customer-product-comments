{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import pandas as pd\n",
    "from cleaning_data import clean_text_vietnamese\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "np.random.seed(17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify customer comments regrading sentiment\n",
    "Problem: Classify Vietnamese customer comments by predicting whether the comments are positive or negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Phobert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")\n",
    "bert_model = AutoModel.from_pretrained(\"vinai/phobert-base\").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get bert embedding from sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_embedding(sentence):\n",
    "    sentence = clean_text_vietnamese(sentence, keep_punct=True)\n",
    "    inputs = tokenizer(sentence, return_tensors='pt', truncation=True, padding=True, max_length=128)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state\n",
    "    sentence_embedding = embeddings.mean(dim=1).squeeze().cpu().numpy()\n",
    "    return sentence_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the accurate of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(test_file,svm_model):\n",
    "    # Load test data\n",
    "    test_data = pd.read_excel(test_file)\n",
    "    \n",
    "    # Ensure column names are lowercase\n",
    "    test_data.columns = test_data.columns.str.lower()\n",
    "    # Get predictions using lowercase column names\n",
    "    X_test = [get_bert_embedding(text) for text in test_data['text']]\n",
    "    y_true = test_data['label']\n",
    "    y_pred = svm_model.predict(X_test)\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    report = classification_report(y_true, y_pred)\n",
    "    \n",
    "    print(f\"\\nAccuracy: {accuracy:.6f}\")\n",
    "    print(\"\\nDetailed Classification Report:\")\n",
    "    print(report)\n",
    "    \n",
    "    return accuracy, report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path_poly = 'svm_model_poly.pkl'\n",
    "model_path_linear = 'svm_model_linear.pkl'\n",
    "model_path_rbf = 'svm_model_rbf.pkl'\n",
    "model_path_logistic_regression = 'model_logistic.pkl'\n",
    "model_path = {\n",
    "    \"Linear SVM\": model_path_linear,\n",
    "    \"Polynomial SVM\": model_path_poly,\n",
    "    \"RBF SVM\": model_path_rbf,\n",
    "    \"Logistic Regression\": model_path_logistic_regression\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Linear SVM:\n",
      "\n",
      "Accuracy: 0.980490\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97       585\n",
      "           1       0.99      0.98      0.99      1414\n",
      "\n",
      "    accuracy                           0.98      1999\n",
      "   macro avg       0.97      0.98      0.98      1999\n",
      "weighted avg       0.98      0.98      0.98      1999\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Polynomial SVM:\n",
      "\n",
      "Accuracy: 0.982991\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97       585\n",
      "           1       1.00      0.98      0.99      1414\n",
      "\n",
      "    accuracy                           0.98      1999\n",
      "   macro avg       0.97      0.98      0.98      1999\n",
      "weighted avg       0.98      0.98      0.98      1999\n",
      "\n",
      "\n",
      "\n",
      "Evaluating RBF SVM:\n",
      "\n",
      "Accuracy: 0.983492\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97       585\n",
      "           1       0.99      0.98      0.99      1414\n",
      "\n",
      "    accuracy                           0.98      1999\n",
      "   macro avg       0.98      0.98      0.98      1999\n",
      "weighted avg       0.98      0.98      0.98      1999\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Logistic Regression:\n",
      "\n",
      "Accuracy: 0.981491\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.97       585\n",
      "           1       1.00      0.98      0.99      1414\n",
      "\n",
      "    accuracy                           0.98      1999\n",
      "   macro avg       0.97      0.99      0.98      1999\n",
      "weighted avg       0.98      0.98      0.98      1999\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for model_name, model_file in model_path.items():\n",
    "    model = joblib.load(model_file)\n",
    "    test_file = \"Testing_dataset.xlsx\"\n",
    "    print(f\"Evaluating {model_name}:\")\n",
    "    accuracy, report = evaluate_model(test_file, model)\n",
    "    results.append({\n",
    "        'Model Name': model_name,\n",
    "        'Model Type': \"SVM\" if \"SVM\" in model_name else \"Logistic Regression\",\n",
    "        'Accuracy (%)': f\"{accuracy * 100:.4f}\"\n",
    "    })\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Comparison Table:\n",
      "╒════╤═════════════════════╤═════════════════════╤════════════════╕\n",
      "│    │ Model Name          │ Model Type          │   Accuracy (%) │\n",
      "╞════╪═════════════════════╪═════════════════════╪════════════════╡\n",
      "│  0 │ Linear SVM          │ SVM                 │        98.049  │\n",
      "├────┼─────────────────────┼─────────────────────┼────────────────┤\n",
      "│  1 │ Polynomial SVM      │ SVM                 │        98.2991 │\n",
      "├────┼─────────────────────┼─────────────────────┼────────────────┤\n",
      "│  2 │ RBF SVM             │ SVM                 │        98.3492 │\n",
      "├────┼─────────────────────┼─────────────────────┼────────────────┤\n",
      "│  3 │ Logistic Regression │ Logistic Regression │        98.1491 │\n",
      "╘════╧═════════════════════╧═════════════════════╧════════════════╛\n"
     ]
    }
   ],
   "source": [
    "comparison_df = pd.DataFrame(results)\n",
    "\n",
    "# Display a pretty table using tabulate\n",
    "print(\"\\nModel Comparison Table:\")\n",
    "print(tabulate(comparison_df, headers='keys', tablefmt='fancy_grid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using RBF kernel for demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = joblib.load('svm_model_rbf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sản phẩm này tệ thế\n",
      "Cảm xúc: Tiêu cực\n",
      "sản phẩm này không tệ\n",
      "Cảm xúc: Tích cực\n",
      "sản phẩm này dùng đã thật, tôi rất thích nó\n",
      "Cảm xúc: Tích cực\n",
      "nếu biết trước công dụng của nó tuyệt vời đến vậy tôi đã mua từ lâu\n",
      "Cảm xúc: Tích cực\n",
      "sản phẩm này dùng rất tệ, dùng được có vài ngày đã hư lên hư xuống, thật đáng thất vọng\n",
      "Cảm xúc: Tiêu cực\n",
      "sản phẩm này không tốt\n",
      "Cảm xúc: Tiêu cực\n",
      "sản phẩm này tốt\n",
      "Cảm xúc: Tích cực\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    input_text = input(\"Nhập câu để kiểm tra cảm xúc (hoặc nhập 'q' để thoát): \")\n",
    "    if input_text == 'q':\n",
    "            break\n",
    "    sentence_embedding = get_bert_embedding(input_text)\n",
    "    predicted_sentiment = svm_model.predict([sentence_embedding])[0]  # Dự đoán 1 câu\n",
    "    print(input_text)\n",
    "    if predicted_sentiment == 0:\n",
    "            print(\"Cảm xúc: Tiêu cực\")\n",
    "    else:    \n",
    "            print(\"Cảm xúc: Tích cực\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
